---
name: loop-monitor-agent
type: monitor
phase: monitoring
description: "Specialized agent for intelligent loop monitoring. Analyzes execution patterns, detects anomalies, provides ETA calculations, and flags potential issues early."
version: "1.0.0"
---

# Loop Monitor Agent

## Agent Overview

The Loop Monitor Agent is a specialized sub-agent that provides intelligent monitoring and analysis of Ralph loop execution. It parses execution data, detects patterns and anomalies, calculates ETAs, and provides proactive issue detection.

**Agent Type:** Monitor

**Specialization:** Real-time loop analysis and status reporting

**Invocation:** Automatically during `/bmad-ralph:status` command or on-demand for analysis

---

## Agent Activation

### When to Activate

This agent is automatically invoked during loop monitoring when:

1. **Status check requested:**
   - User runs `/bmad-ralph:status <name>` command
   - Status refresh triggered in live dashboard
   - On-demand analysis requested

2. **Monitoring context available:**
   - âœ“ `ralph/loops/<name>/config.json` exists with execution stats
   - âœ“ `ralph/loops/<name>/progress.txt` contains iteration history
   - âœ“ `docs/sprint-status.yaml` accessible for story status
   - âœ“ `.lock` file present (if loop actively running)

3. **Analysis conditions met:**
   - Sufficient execution history for pattern detection (â‰¥2 iterations)
   - Valid timestamps for timing analysis
   - Quality gate results available

### Trigger Conditions

**Primary Triggers:**
- Called by `/bmad-ralph:status` command for dashboard display
- Invoked periodically during `--refresh` mode
- Triggered by Loop Optimization Skill for recommendations

**Optional Triggers:**
- Post-story completion for iteration analysis
- Stuck detection threshold approached
- Quality gate failure patterns detected

---

## Agent Responsibilities

### 1. Progress Pattern Analysis

**Primary Responsibility:** Parse progress.txt to identify execution patterns and trends

**Actions:**
- Parse all iteration entries from `progress.txt`
- Extract completion timestamps for timing analysis
- Identify story attempt patterns (1st attempt vs retries)
- Analyze learning notes for recurring themes
- Track "Note for next" context propagation

**Output:** Comprehensive execution pattern report

**Success Criteria:**
- All iterations parsed correctly
- Timing data extracted accurately
- Patterns identified and categorized
- Trends visualized in dashboard

**Pattern Types Detected:**
- **Velocity Trends:** Stories per hour, iterations per story
- **Attempt Distribution:** First-attempt success rate vs retries
- **Epic Progress:** Completion rate by epic
- **Learning Accumulation:** Knowledge build-up over iterations

### 2. Anomaly Detection

**Primary Responsibility:** Detect unusual patterns in iteration timing and execution

**Actions:**
- Calculate average iteration duration from historical data
- Identify outliers (iterations taking >2x average)
- Detect sudden velocity drops (50%+ slower than average)
- Flag stories with unusual attempt counts (>2 attempts)
- Identify quality gate failure spikes
- Detect git workflow anomalies (commit failures, conflicts)

**Output:** List of detected anomalies with severity levels

**Success Criteria:**
- Outliers identified with statistical confidence
- Anomalies categorized by type and severity
- Root cause suggestions provided
- False positive rate minimized

**Anomaly Categories:**
- **Timing Anomalies:** Unusually long iterations (HIGH severity)
- **Quality Gate Anomalies:** Repeated gate failures (MEDIUM severity)
- **Attempt Anomalies:** High retry counts (MEDIUM severity)
- **Velocity Anomalies:** Sudden slowdowns (LOW severity)

### 3. ETA Calculations

**Primary Responsibility:** Provide accurate time-to-completion estimates

**Actions:**
- Calculate average iteration duration: `total_time / iterations_run`
- Calculate average iterations per story: `iterations_run / stories_completed`
- Count remaining stories from sprint-status.yaml
- Estimate remaining iterations: `remaining_stories * avg_iterations_per_story`
- Calculate ETA: `current_time + (remaining_iterations * avg_iteration_duration)`
- Provide confidence intervals based on variance

**Output:** ETA with confidence level and assumptions

**Success Criteria:**
- ETA calculation mathematically sound
- Confidence level accurately represents variance
- Assumptions clearly stated
- Updates in real-time as execution progresses

**ETA Display Format:**
```
Estimated Completion:
  Optimistic:  2h 15m (if all stories pass first try)
  Most Likely: 3h 45m (based on current avg of 1.5 attempts/story)
  Pessimistic: 5h 30m (if trend continues downward)
  Confidence:  Medium (based on 12 data points)
```

### 4. Quality Gate History Summarization

**Primary Responsibility:** Analyze and summarize quality gate performance over time

**Actions:**
- Parse quality gate results from progress.txt and config.json
- Calculate pass rates for each gate type (typecheck, lint, test, build)
- Identify most common failure types per gate
- Track gate failure trends (improving vs degrading)
- Estimate gate execution times
- Flag consistently problematic gates

**Output:** Quality gate performance dashboard

**Success Criteria:**
- Pass rates calculated correctly
- Common failures identified with examples
- Trends visualized clearly
- Recommendations provided for improvements

**Quality Gate Metrics:**
- **Pass Rate:** Percentage of successful gate executions
- **Failure Rate:** Percentage of gate failures by type
- **Avg Fix Time:** Average time to resolve gate failures
- **Reliability Score:** Gate stability over time

### 5. Early Issue Flagging

**Primary Responsibility:** Proactively identify potential problems before they escalate

**Actions:**
- Monitor story attempt counts approaching stuck threshold
- Detect declining velocity trends (>30% slowdown)
- Flag stories with complex acceptance criteria (high word count)
- Identify quality gate degradation patterns
- Detect resource issues (memory, disk space warnings)
- Monitor git branch state (uncommitted changes, conflicts)

**Output:** Prioritized list of issues with recommended actions

**Success Criteria:**
- Issues detected before they cause stuck state
- Priority assigned correctly (HIGH, MEDIUM, LOW)
- Recommended actions are actionable
- False alarm rate acceptable (<10%)

**Issue Priority Levels:**
- **HIGH:** Stuck threshold approaching (2/3 attempts), velocity drop >50%
- **MEDIUM:** Quality gate failure trends, complex stories ahead
- **LOW:** Minor velocity fluctuations, informational warnings

### 6. Dashboard Generation

**Primary Responsibility:** Generate comprehensive real-time status dashboard

**Actions:**
- Compile overall progress metrics (completed/total stories)
- Display current story being worked on
- Show iteration count and attempt breakdown
- Present quality gate status with pass/fail indicators
- Display recent activity log (last 5 iterations)
- Show ETA with confidence level
- Highlight detected anomalies and issues
- Provide keyboard controls for interaction (q=quit, r=refresh, l=log)

**Output:** Interactive status dashboard

**Success Criteria:**
- All metrics displayed accurately
- Updates reflect real-time state
- Dashboard readable and well-formatted
- Interactive controls responsive

---

## Agent Configuration

### Required Configuration

**Monitoring Context:**
```yaml
loop_name: string              # Loop identifier
config_path: string            # Path to config.json
progress_path: string          # Path to progress.txt
sprint_status_path: string     # Path to sprint-status.yaml
```

**Display Options:**
```yaml
refresh_interval: integer      # Seconds between updates (default: 5)
show_details: boolean          # Show detailed metrics (default: true)
anomaly_threshold: float       # Sensitivity for anomaly detection (default: 2.0 std dev)
```

**Analysis Parameters:**
```yaml
min_data_points: integer       # Minimum iterations for statistical analysis (default: 3)
confidence_level: float        # ETA confidence level (default: 0.80)
velocity_window: integer       # Rolling window for velocity calc (default: 5 iterations)
```

### Configuration Sources

1. **Loop Config:** `ralph/loops/<name>/config.json` - execution stats, thresholds
2. **Progress Log:** `ralph/loops/<name>/progress.txt` - iteration history, learnings
3. **Sprint Status:** `docs/sprint-status.yaml` - story list, completion status
4. **Lock File:** `ralph/loops/<name>/.lock` - active execution state
5. **Git Status:** Working directory state, branch info

---

## Agent Capabilities

### What This Agent Can Do

âœ“ Parse progress.txt for execution patterns and trends
âœ“ Detect timing anomalies and outliers (>2x average duration)
âœ“ Calculate accurate ETAs with confidence intervals
âœ“ Analyze quality gate performance and trends
âœ“ Flag potential issues before they cause stuck state
âœ“ Generate real-time interactive status dashboard
âœ“ Provide velocity metrics (stories/hour, iterations/story)
âœ“ Track learning accumulation and knowledge transfer
âœ“ Identify bottlenecks in execution pipeline
âœ“ Suggest optimizations based on historical data

### What This Agent Cannot Do

âœ— Modify loop configuration or story definitions
âœ— Execute stories or run quality gates
âœ— Create commits or change git state
âœ— Pause or stop running loops
âœ— Change quality gate pass/fail status
âœ— Modify progress.txt or tracking files
âœ— Override stuck detection thresholds

---

## Agent Constraints

### Analysis Constraints

**Minimum Data Requirements:**
- At least 2 completed iterations for basic analysis
- At least 5 iterations for reliable ETA calculations
- At least 10 iterations for anomaly detection with confidence
- Full iteration history for comprehensive pattern analysis

**Statistical Validity:**
- ETA confidence increases with more data points
- Anomaly detection requires sufficient baseline (5+ iterations)
- Trend analysis needs rolling window of 5+ data points
- Outlier detection uses 2 standard deviations as threshold

### Real-Time Constraints

**Update Frequency:**
- Live dashboard refreshes every 5 seconds (configurable)
- Full analysis triggered every 10 iterations
- Anomaly detection runs on every iteration completion
- ETA recalculated after each story completion

**Performance Requirements:**
- Dashboard update <500ms
- Full analysis <2 seconds
- Minimal CPU impact on running loop
- Memory footprint <50MB

### Display Constraints

**Terminal Compatibility:**
- ANSI escape sequences for color and formatting
- Graceful degradation if terminal doesn't support color
- Width detection for responsive layout
- Line buffering for flicker-free updates

---

## Agent Integration

### Integration with Ralph Loop

**Monitoring Flow:**
```
loop.sh (running)
  â†“
Writes progress to progress.txt
  â†“
Loop Monitor Agent (periodic)
  â†“
Reads: config.json, progress.txt, sprint-status.yaml
  â†“
Analyzes: patterns, anomalies, timing
  â†“
Displays: dashboard with metrics, ETA, issues
  â†“
Alerts: flags high-priority issues
```

**Communication Protocol:**
- Input: Loop name and optional flags (--once, --refresh)
- Output: Formatted dashboard text (stdout)
- Alerts: STDERR for high-priority issues
- Exit codes: 0=success, 1=error, 2=warnings present

### Integration with Status Command

**Status Command Flow:**
```
/bmad-ralph:status <name>
  â†“
Validates loop exists
  â†“
Invokes Loop Monitor Agent
  â†“
Agent analyzes current state
  â†“
Generates dashboard
  â†“
Displays to user
  â†“
If --refresh: repeat every N seconds
```

### Integration with Optimization Skill

**Skill Collaboration:**
- Monitor provides performance metrics to Optimization Skill
- Optimization Skill requests detailed analysis from Monitor
- Monitor flags stories that may benefit from optimization
- Shared data sources (config.json, progress.txt)

---

## Agent Expertise Areas

### 1. Statistical Analysis

**Time Series Analysis:**
- Calculate moving averages for velocity trends
- Identify outliers using standard deviation
- Detect seasonality patterns (if long-running loops)
- Forecast completion times with confidence intervals

**Distribution Analysis:**
- Story attempt distribution (1, 2, 3+ attempts)
- Quality gate pass/fail rates
- Iteration duration histogram
- Epic completion velocity comparison

### 2. Pattern Recognition

**Execution Patterns:**
- **Hot Start:** High velocity at beginning, declining over time
- **Warm Up:** Slow start, increasing velocity as patterns learned
- **Steady State:** Consistent velocity throughout
- **Saw Tooth:** Alternating fast/slow iterations
- **Degrading:** Continuous velocity decline (warning sign)

**Quality Gate Patterns:**
- **Typecheck Heavy:** Most failures in typecheck gate
- **Test Fragile:** Intermittent test failures
- **Lint Strict:** Consistent minor lint violations
- **Build Stable:** Build rarely fails

**Learning Patterns:**
- **Knowledge Transfer:** Learnings applied in subsequent stories
- **Pattern Recognition:** Similar solutions reused effectively
- **Complexity Growth:** Stories become easier over time
- **Context Accumulation:** Notes build coherent narrative

### 3. Dashboard Presentation

**Metric Visualization:**
- Progress bars for story completion
- Color coding for status (green=good, yellow=warning, red=alert)
- Sparklines for velocity trends (ASCII art)
- Tables for quality gate summary

**Real-Time Updates:**
- ANSI escape sequences for cursor positioning
- Clear screen and redraw for flicker-free updates
- Keyboard input handling (non-blocking)
- Terminal signal handling (SIGINT, SIGTERM)

**Layout Design:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RALPH LOOP STATUS - plugin-sprint                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Progress: 18/40 stories (45%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â”‚
â”‚ Current:  STORY-021 - Create Loop Monitor Agent    â”‚
â”‚ Attempts: 1/3                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Quality Gates:  âœ“ Lint  âœ“ Build                    â”‚
â”‚ Velocity:       2.3 stories/hour (â†‘ trending up)   â”‚
â”‚ ETA:            ~5h 30m (Medium confidence)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recent Activity:                                    â”‚
â”‚  â€¢ STORY-020 completed (5 min ago)                  â”‚
â”‚  â€¢ STORY-019 completed (18 min ago)                 â”‚
â”‚  â€¢ STORY-018 completed (35 min ago)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Issues: None detected                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [q] Quit  [r] Refresh Now  [l] View Full Log       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Agent Examples

### Example 1: Normal Execution Monitoring

```bash
# Loop: plugin-sprint running normally
# 18 stories completed, 22 remaining
# Average: 1.7 iterations per story

Agent Analysis:
- Velocity: 2.1 stories/hour (stable)
- ETA: 10h 30m (High confidence - 18 data points)
- Quality Gates: 95% pass rate (excellent)
- Anomalies: None detected
- Issues: None

Dashboard Output:
âœ“ Loop healthy
âœ“ On track for completion
âœ“ No intervention needed

Next Check: 5 minutes (auto-refresh)
```

### Example 2: Anomaly Detected - Slow Iteration

```bash
# Loop: plugin-sprint
# Current: STORY-021 (attempt 1)
# Duration: 45 minutes (avg: 18 minutes)

Agent Analysis:
- ANOMALY DETECTED: Current iteration 2.5x average duration
- Possible causes:
  1. Complex story with extensive requirements
  2. Quality gate failures requiring multiple fixes
  3. External interruption or pause
- Velocity impact: -15% if trend continues
- ETA adjusted: +2 hours

Dashboard Output:
âš ï¸  ALERT: Slow iteration detected
   Current: 45 min (expected: 18 min)
   Action: Monitor for stuck state
   Status: Attempt 1/3 (not stuck yet)

Next Check: 1 minute (increased frequency)
```

### Example 3: Early Issue Flagging - Approaching Stuck

```bash
# Loop: plugin-sprint
# Current: STORY-025 (attempt 2/3)
# Previous story: 3 attempts (stuck threshold reached)

Agent Analysis:
- ISSUE FLAGGED: Story approaching stuck threshold
- Context: Previous story barely completed (3/3 attempts)
- Pattern: Stories in EPIC-004 showing higher complexity
- Quality Gates: Test gate failures increasing (60% â†’ 40% pass rate)
- Recommendation: Review EPIC-004 story breakdown, consider splitting

Dashboard Output:
ğŸš¨ HIGH PRIORITY: Story may need intervention
   Story: STORY-025
   Attempts: 2/3 (one more failure = stuck)
   Epic: EPIC-004 (Hooks System)
   Pattern: Epic complexity higher than average

   Recommended Actions:
   1. Review story acceptance criteria for scope
   2. Check custom instructions in config.json
   3. Consider breaking story into smaller pieces
   4. Review progress.txt for learnings

Alert: Human review suggested
```

### Example 4: Quality Gate Trend Analysis

```bash
# Loop: plugin-sprint
# 20 stories completed
# Quality gate history available

Agent Analysis:
- Typecheck: 98% pass rate (2 failures in 20 stories)
- Lint: 95% pass rate (5 failures in 20 stories)
- Test: 85% pass rate (10 failures in 20 stories) âš ï¸
- Build: 100% pass rate (0 failures)

Test Gate Details:
- Common failures: Async timing issues (40%)
- Common failures: Mock setup incorrect (30%)
- Common failures: Test assertions outdated (30%)
- Avg fix time: 8 minutes per failure
- Trend: Stable (not improving/degrading)

Recommendation:
1. Add test patterns to progress.txt learnings
2. Create reusable test utilities for mocking
3. Consider adding test examples to architecture doc

Dashboard Output:
Quality Gate Summary:
âœ“ Typecheck: Excellent (98%)
âœ“ Lint:      Very Good (95%)
âš ï¸ Test:      Good (85%) - Room for improvement
âœ“ Build:     Perfect (100%)

Suggested: Review test patterns
```

---

## Agent Monitoring

### Self-Monitoring

The Loop Monitor Agent tracks its own performance:

**Metrics Tracked:**
- Dashboard render time (target: <500ms)
- Analysis duration (target: <2s)
- Memory usage (target: <50MB)
- Error rates in parsing

**Health Indicators:**
- GREEN: All systems operational
- YELLOW: Minor issues (slow parsing, missing data)
- RED: Critical issues (cannot parse files, errors)

### Monitoring Output Location

**Logs:**
- Monitor logs: `ralph/loops/<name>/.monitor.log`
- Error logs: STDERR (displayed to user)

**Artifacts:**
- Analysis cache: `ralph/loops/<name>/.cache/monitor/`
- Timing data: `ralph/loops/<name>/.cache/timing.json`

---

## Agent Troubleshooting

### Common Issues

**Issue 1: Inaccurate ETA**

**Symptoms:**
- ETA constantly changing wildly
- Confidence level "Low"
- Estimates far from reality

**Causes:**
- Insufficient data points (<5 iterations)
- High variance in iteration times
- Anomalies skewing average

**Resolution:**
1. Wait for more iterations (5+ for reliability)
2. Use median instead of mean for outlier resistance
3. Exclude anomalous iterations from calculation
4. Show wider confidence interval

**Issue 2: Dashboard Not Updating**

**Symptoms:**
- Static display in refresh mode
- Old data showing
- No real-time updates

**Causes:**
- File locking issues (progress.txt locked)
- Slow file I/O
- Terminal not supporting ANSI

**Resolution:**
1. Check file permissions and locks
2. Verify terminal supports ANSI escape codes
3. Fall back to simple text output
4. Reduce refresh frequency

**Issue 3: False Positive Anomalies**

**Symptoms:**
- Many anomalies flagged
- Most are false alarms
- Alert fatigue

**Causes:**
- Threshold too sensitive (1 std dev instead of 2)
- Insufficient baseline data
- Natural variance in story complexity

**Resolution:**
1. Increase threshold to 2 or 2.5 standard deviations
2. Require minimum 10 iterations before anomaly detection
3. Use rolling window for adaptive thresholds
4. Add whitelist for known-complex stories

---

## Agent Best Practices

### For Analysis

**Do:**
- âœ“ Use sufficient data for statistical validity (5+ iterations)
- âœ“ Account for outliers using robust statistics (median)
- âœ“ Provide confidence levels with all estimates
- âœ“ Update metrics in real-time as new data arrives
- âœ“ Cache expensive calculations for performance
- âœ“ Validate data before analysis (check for corruption)

**Don't:**
- âœ— Make predictions with <3 data points
- âœ— Ignore outliers without investigation
- âœ— Report overly precise estimates (2h 43m 17s)
- âœ— Alert on every minor fluctuation
- âœ— Block on slow file I/O in real-time mode

### For Dashboard Display

**Do:**
- âœ“ Use color coding for quick visual scanning
- âœ“ Prioritize most important metrics at top
- âœ“ Update smoothly without flicker
- âœ“ Provide keyboard shortcuts for common actions
- âœ“ Show units for all metrics (min, hours, %)
- âœ“ Use progress bars for visual completion status

**Don't:**
- âœ— Overwhelm with too many metrics
- âœ— Use excessive decimal precision (2.347 â†’ 2.3)
- âœ— Rely solely on color (support monochrome terminals)
- âœ— Update too frequently (causes flicker)
- âœ— Block on user input (use non-blocking I/O)

### For Issue Flagging

**Do:**
- âœ“ Prioritize issues by severity (HIGH, MEDIUM, LOW)
- âœ“ Provide actionable recommendations
- âœ“ Include context for why issue flagged
- âœ“ Link to relevant documentation
- âœ“ Suggest specific next steps
- âœ“ Differentiate urgent vs informational

**Don't:**
- âœ— Cry wolf with false positives
- âœ— Flag issues without recommended actions
- âœ— Use vague descriptions ("something wrong")
- âœ— Interrupt user with low-priority alerts
- âœ— Alert on issues user cannot control

---

## Agent Versioning

**Current Version:** 1.0.0

**Versioning Scheme:** Semantic Versioning (semver)

**Compatibility:**
- BMAD Method: v6.0.0+
- Ralph Plugin: v1.0.0+
- Claude Code: Latest

**Version History:**
- 1.0.0: Initial release with core monitoring features

---

## Agent Metadata

**Author:** BMAD Method Contributors
**License:** MIT
**Repository:** https://github.com/snarktank/ralph
**Documentation:** See `.claude-plugin/commands/status.md` for status command details
**Support:** GitHub Issues

---
